import os
import json
import re
import requests

# Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ Ù†Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§
TARGETS = ["beIN", "SSC", "Alkass", "AD SPORT", "Yalla", "Shoot", "Sport", "Live"]
OUTPUT_FILE = "channels.json"

def clean_url(url):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ù† Ø£ÙŠ ØªØ´ÙÙŠØ± JavaScript"""
    url = url.replace('\\/', '/').replace('\\', '')
    if url.startswith('//'):
        url = 'https:' + url
    return url

def scan_files():
    print("ğŸ•µï¸ Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³Ø­ÙˆØ¨Ø© ÙˆÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±...")
    all_channels = []
    
    # 1. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ (JS, HTML, Text)
    for root, dirs, files in os.walk("."):
        for file in files:
            if file.endswith((".js", ".html", ".txt", ".json", ".m3u8")):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        # Ø§Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ø±Ø§Ø¨Ø· ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ù€ m3u8 Ø£Ùˆ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© live
                        # Ø¬Ù„Ø¨ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª Ø¯Ø§Ø®Ù„ " " Ø£Ùˆ ' '
                        links = re.findall(r'["\'](https?[:\/\\]+[^\s"\']+\.m3u8[^\s"\']*)["\']', content)
                        
                        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙŠ Ù„Ø§ ØªÙ†ØªÙ‡ÙŠ Ø¨Ù€ m3u8 ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØªØ¨Ø¯Ùˆ ÙƒØ±ÙˆØ§Ø¨Ø· Ø¨Ø«
                        stream_links = re.findall(r'["\'](https?[:\/\\]+[^\s"\']+/live/[^\s"\']*)["\']', content)
                        
                        for link in (links + stream_links):
                            cleaned = clean_url(link)
                            all_channels.append({
                                "name": f"Ù‚Ù†Ø§Ø© Ù…Ø³ØªØ®Ø±Ø¬Ø© ({file[:10]}...)",
                                "url": cleaned,
                                "logo": "https://cdn-icons-png.flaticon.com/512/716/716429.png"
                            })
                            print(f"ğŸ¯ ÙˆØ¬Ø¯Ù†Ø§ Ø±Ø§Ø¨Ø· ÙÙŠ: {file}")
                except: continue

    # 2. Ø¥Ø¶Ø§ÙØ© Ù…ØµØ§Ø¯Ø± Ø¹Ø§Ù„Ù…ÙŠØ© ÙƒØ§Ø­ØªÙŠØ§Ø· (Ù„Ø¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù„Ù† ÙŠÙƒÙˆÙ† ÙØ§Ø±ØºØ§Ù‹)
    backup_sources = [
        "https://iptv-org.github.io/iptv/countries/ar.m3u",
        "https://raw.githubusercontent.com/skid9000/All-In-One-IPTV/main/All-In-One-IPTV.m3u"
    ]
    for src in backup_sources:
        try:
            r = requests.get(src, timeout=10)
            if r.status_code == 200:
                m3u_links = re.findall(r'#EXTINF.*?,(.*?)\n(http.*)', r.text)
                for name, url in m3u_links:
                    if any(t.lower() in name.lower() for t in TARGETS):
                        all_channels.append({"name": name.strip(), "url": url.strip(), "logo": ""})
        except: continue

    return all_channels

def save_and_verify(channels):
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
    unique = {c['url']: c for c in channels}.values()
    
    # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù…Ù„Ù
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(unique), f, ensure_ascii=False, indent=4)
    print(f"âœ… ØªÙ… Ø­ÙØ¸ {len(unique)} Ù‚Ù†Ø§Ø© ÙÙŠ channels.json")

if __name__ == "__main__":
    found = scan_files()
    save_and_verify(found)
