import requests
import json
import re

# ุงููููุงุช ุงูุชู ุณูุจุญุซ ุนููุง ุงูุฑูุจูุช ูู ูู GitHub ูุงููุตุงุฏุฑ
TARGET_CHANNELS = ["beIN", "SSC", "Alkass", "AD SPORT", "KSA SPORT", "Oman Sport", "Dubai Sport", "Arryadia"]
OUTPUT_FILE = "channels.json"

def is_live(url):
    """ูุญุต ุณุฑูุน ุฌุฏุงู ููุฑุงุจุท ูุถูุงู ุนุฏู ุชุนููู ุงูุณูุฑูุจุช"""
    try:
        # ูุณุชุฎุฏู HEAD ุจุฏูุงู ูู GET ูุณุฑุนุฉ ุงููุญุต
        r = requests.head(url, timeout=3)
        return r.status_code < 400
    except:
        return False

def fetch_channels():
    print("๐ ุฌุงุฑู ุงูุจุญุซ ุนู ุงููููุงุช ุงูุฑูุงุถูุฉ ูู GitHub ูุงููุตุงุฏุฑ ุงูุนุงูููุฉ...")
    all_channels = []
    
    # ูุตุงุฏุฑ IPTV ุถุฎูุฉ ููุญุฏุซุฉ ุจุงุณุชูุฑุงุฑ
    sources = [
        "https://iptv-org.github.io/iptv/countries/ar.m3u",
        "https://raw.githubusercontent.com/skid9000/All-In-One-IPTV/main/All-In-One-IPTV.m3u",
        "https://raw.githubusercontent.com/byte-capsule/sk_iptv/main/sk_iptv.m3u",
        "https://raw.githubusercontent.com/Moebis-Iptv/M3U/main/Arabic.m3u",
        "https://raw.githubusercontent.com/Hasibul-Hasan-1/Hasibul-Hasan-1/main/Hasibul-Hasan-1.m3u"
    ]

    for source in sources:
        try:
            response = requests.get(source, timeout=10)
            if response.status_code == 200:
                lines = response.text.split('\n')
                name, logo = "", "https://cdn-icons-png.flaticon.com/512/716/716429.png"
                
                for i, line in enumerate(lines):
                    if "#EXTINF" in line:
                        # ุงุณุชุฎุฑุงุฌ ุงูุงุณู ูุงูููุฌู ุจุฏูุฉ
                        name_match = re.search('tvg-name="(.*?)"', line) or re.search(',(.*?)$', line)
                        logo_match = re.search('tvg-logo="(.*?)"', line)
                        if name_match: name = name_match.group(1).strip()
                        if logo_match: logo = logo_match.group(1)
                        
                        if i + 1 < len(lines):
                            url = lines[i+1].strip()
                            if url.startswith("http"):
                                # ูุญุต ุงูุงุณู (ุชุฌุงูู ุญุงูุฉ ุงูุฃุญุฑู)
                                if any(t.lower() in name.lower() for t in TARGET_CHANNELS):
                                    # ุงููุญุต ุงูุญูููู ููุฑุงุจุท
                                    if is_live(url):
                                        print(f"โ ูุฌุฏูุง ููุงุฉ ุดุบุงูุฉ: {name}")
                                        all_channels.append({"name": name, "url": url, "logo": logo})
        except: continue

    # ุฅุฒุงูุฉ ุงูุชูุฑุงุฑ
    unique_channels = {c['url']: c for c in all_channels}.values()
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(unique_channels), f, ensure_ascii=False, indent=4)
    
    print(f"โจ ุชู ุงูุชุญุฏูุซ! ุฅุฌูุงูู ุงููููุงุช ุงูุดุบุงูุฉ ุงูููุชุดูุฉ: {len(unique_channels)}")

if __name__ == "__main__":
    fetch_channels()
