import os
import json
import re
import requests
import base64

# Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© Ù„Ù„Ø¨Ø­Ø«
TARGET_CHANNELS = ["beIN", "SSC", "Alkass", "AD SPORT", "ON TIME", "Sport", "Yalla"]
OUTPUT_FILE = "channels.json"

def deobfuscate_logic(text):
    """Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø®ÙÙŠØ© (Base64 Ø£Ùˆ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ù‚Ø·Ø¹Ø©)"""
    found = []
    # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Base64 (Ø´Ø§Ø¦Ø¹ ÙÙŠ Ù…Ù„ÙØ§Øª JS Ø§Ù„Ù…Ø´ÙØ±Ø©)
    b64_matches = re.findall(r'["\']([A-Za-z0-9+/]{20,}=*)["\']', text)
    for b in b64_matches:
        try:
            decoded = base64.b64decode(b).decode('utf-8')
            if "http" in decoded:
                found.append(decoded)
        except: continue
    return found

def extract_from_files():
    print("ğŸ•µï¸ Ø¬Ø§Ø±ÙŠ ÙØ­Øµ ÙˆÙÙƒ ØªØ´ÙÙŠØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³Ø­ÙˆØ¨Ø©...")
    all_found = []
    
    # ÙŠÙ…Ø± Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯
    for root, dirs, files in os.walk("."):
        for file in files:
            # Ù†ÙØ­Øµ Ù…Ù„ÙØ§Øª JS, HTML, CSS ÙˆØ­ØªÙ‰ Ø§Ù„Ù€ TXT
            if file.endswith((".js", ".html", ".txt", ".json")):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        # 1. Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· m3u8
                        direct_links = re.findall(r'(https?://[^\s"\']+\.m3u8[^\s"\']*)', content)
                        
                        # 2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Ù…Ø®ÙÙŠØ© (Ø¨Ø¯ÙˆÙ† Ø§Ù…ØªØ¯Ø§Ø¯ ÙˆØ§Ø¶Ø­)
                        proxy_links = re.findall(r'(https?://[^\s"\']+/live/[^\s"\']*)', content)
                        
                        # 3. Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ (Base64)
                        hidden_links = deobfuscate_logic(content)
                        
                        total_links = direct_links + proxy_links + hidden_links
                        
                        for link in total_links:
                            # ÙÙ„ØªØ±Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© ÙÙ‚Ø·
                            # Ø¨Ù…Ø§ Ø£Ù†Ù†Ø§ Ù†Ø³Ø­Ø¨ Ù…Ù† ÙŠÙ„Ø§ Ø´ÙˆØªØŒ Ø³Ù†Ø¹ØªØ¨Ø± Ø£ÙŠ Ø±Ø§Ø¨Ø· m3u8 Ù‡Ùˆ Ù‚Ù†Ø§Ø© Ø±ÙŠØ§Ø¶ÙŠØ© Ù…Ø­ØªÙ…Ù„Ø©
                            all_found.append({
                                "name": f"Ù‚Ù†Ø§Ø© Ù…Ø³ØªØ®Ø±Ø¬Ø© ({file})",
                                "url": link.replace("\\/", "/"), # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ù† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù‡Ø±ÙˆØ¨
                                "logo": "https://cdn-icons-png.flaticon.com/512/716/716429.png"
                            })
                            print(f"ğŸ¯ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· ÙÙŠ: {file}")
                except: continue
    return all_found

def fetch_channels():
    # Ø¬Ù„Ø¨ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
    channels = extract_from_files()
    
    # Ø¥Ø¶Ø§ÙØ© Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙØ±Ø§Øº Ø§Ù„Ù…ÙˆÙ‚Ø¹
    sources = [
        "https://raw.githubusercontent.com/skid9000/All-In-One-IPTV/main/All-In-One-IPTV.m3u",
        "https://iptv-org.github.io/iptv/countries/ar.m3u"
    ]
    
    for src in sources:
        try:
            r = requests.get(src, timeout=10)
            # (ÙƒÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† m3u Ø§Ù„Ù…Ø¹ØªØ§Ø¯...)
        except: continue

    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙˆØ­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø±
    unique = {c['url']: c for c in channels}.values()
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(unique), f, ensure_ascii=False, indent=4)
    print(f"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¨Ø­Ø«. ÙˆØ¬Ø¯Ù†Ø§ {len(unique)} Ù‚Ù†Ø§Ø©.")

if __name__ == "__main__":
    fetch_channels()
