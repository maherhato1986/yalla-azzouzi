import os
import json
import re
import requests

OUTPUT_FILE = "channels.json"

def fetch_all():
    all_channels = []
    print("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø¨Ø¯Ø¡ Ø¨Ø¬Ù„Ø¨ Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚Ù†ÙˆØ§Øª...")

    # Ù‚Ù†ÙˆØ§Øª "Ø¶Ù…Ø§Ù† Ø¹Ù…Ù„ Ø§Ù„Ù…ÙˆÙ‚Ø¹" (Ø£Ø®Ø¨Ø§Ø± ÙˆÙ…Ù†ÙˆØ¹Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ©) ØªØ¹Ù…Ù„ 24 Ø³Ø§Ø¹Ø©
    all_channels.append({"name": "Al Jazeera (Live)", "url": "https://live-hls-web-aje.getaj.net/AJE/index.m3u8", "logo": "https://upload.wikimedia.org/wikipedia/en/f/f2/Aljazeera_eng.png"})
    all_channels.append({"name": "BBC Arabic", "url": "https://vs-hls-push-ww-live.akamaized.net/x=4/i=static/bbc_arabic_tv/main.m3u8", "logo": ""})
    all_channels.append({"name": "TRT Arabic", "url": "https://tv-trtarabic.medyahizmetleri.com/live/hls/trt_arabic.m3u8", "logo": ""})

    # 1. ÙØ­Øµ Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ù…Ø³Ø­ÙˆØ¨Ø©
    for root, dirs, files in os.walk("."):
        for file in files:
            if file.endswith((".js", ".html", ".txt", ".json")):
                try:
                    with open(os.path.join(root, file), 'r', encoding='utf-8') as f:
                        content = f.read()
                        # ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ù…Ø§Ø¦Ù„Ø§Øª Ø§Ù„Ø¹ÙƒØ³ÙŠØ© Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ Cloudflare
                        links = re.findall(r'https?[:\/\\]+[^\s"\']+\.m3u8[^\s"\']*', content)
                        for l in links:
                            clean_url = l.replace('\\/', '/').replace('\\', '')
                            all_channels.append({"name": f"Ù‚Ù†Ø§Ø© Ù…Ø³ØªØ®Ø±Ø¬Ø© ({file[:5]})", "url": clean_url, "logo": ""})
                except: continue

    # 2. Ø¬Ù„Ø¨ Ù…Ø¦Ø§Øª Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ù† Ù…ØµØ§Ø¯Ø± GitHub Ø§Ù„Ø¹Ø§Ù…Ø©
    sources = [
        "https://iptv-org.github.io/iptv/countries/ar.m3u",
        "https://raw.githubusercontent.com/Moebis-Iptv/M3U/main/Arabic.m3u"
    ]
    for src in sources:
        try:
            r = requests.get(src, timeout=10)
            matches = re.findall(r'#EXTINF.*?,(.*?)\n(http.*)', r.text)
            for name, url in matches:
                all_channels.append({"name": name.strip(), "url": url.strip(), "logo": ""})
        except: pass

    # Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ­ÙØ¸ Ø£ÙˆÙ„ 500 Ù‚Ù†Ø§Ø© ÙÙ‚Ø·
    unique = {c['url']: c for c in all_channels}.values()
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(unique)[:500], f, ensure_ascii=False, indent=4)
    
    print(f"âœ… ØªÙ… Ø­ÙØ¸ {len(list(unique)[:500])} Ù‚Ù†Ø§Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù.")

if __name__ == "__main__":
    fetch_all()
